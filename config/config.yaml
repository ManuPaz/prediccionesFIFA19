preprocessing:
  #  preprocesado que se puede generalizar a otros dataframes

  # columnas para eliminar
  columns_drop: [ "Unnamed:0" ]
  #conversion de Unidades
  #para altura dos factores: pies a metros y pulgadas a metros, para ancho un factor: libras a kg
  unidades_conversion: { "Height": { "separador": "'", "factor_conv1": 0.3048, "factor_conv2": 0.0254 },
                         "Weight": { "unidad": "lbs", "factor_conv": 0.4536 }, }


#variables que se van a utilizar para predecir cada feature
variables_predictoras:
  Wage: [ "InternationalReputation", "Reactions",
          "Composure", "BallControl", "GKPositioning",
          "ShortPassing", "Interceptions", "Finishing",
          "GKKicking", "HeadingAccuracy", "SkillMoves",
          "LongPassing", "GKHandling", "Vision",
          "GKReflexes", "GKDiving", "Dribbling",
  ]

  PositionGrouped: [ "BallControl", "Penalties", "GKPositioning",
                     "SlidingTackle", "StandingTackle", "Marking",
                     "ShortPassing", "Jumping", "Interceptions",
                     "Finishing" ,"GKKicking" ,"HeadingAccuracy",
                     "Aggression" ,"LongPassing", "GKHandling",
                     "Volleys" ,"Vision" ,"LongShots" ,"GKReflexes",
                     "GKDiving" ,"Positioning" ]
  Position: [ "InternationalReputation", "Reactions", "Overall",
           "BallControl", "Penalties", "GKPositioning",
           "SlidingTackle", "StandingTackle",
           "ShortPassing", "Jumping", "Interceptions",
           "Finishing", "GKKicking", "HeadingAccuracy",
           "Aggression", "LongPassing", "GKHandling",
           "Volleys", "Vision", "LongShots",
           "GKReflexes", "GKDiving", "Positioning",
           "SkillMoves" ,"Dribbling" ,"FKAccuracy",
           "Marking" ,"Balance" ,"Curve" ,"Acceleration",
           "Crossing", "Stamina", "Agility" ,"ShotPower",
           "SprintSpeed" ,"Strength","PreferredFoot"
        ]

  todas: [ "InternationalReputation", "Reactions", "Overall",
           "BallControl", "Penalties", "GKPositioning",
           "SlidingTackle", "StandingTackle",
           "ShortPassing", "Jumping", "Interceptions",
           "Finishing", "GKKicking", "HeadingAccuracy",
           "Aggression", "LongPassing", "GKHandling",
           "Volleys", "Vision", "LongShots",
           "GKReflexes", "GKDiving", "Positioning",
           "SkillMoves" ,"Dribbling" ,"FKAccuracy",
           "Marking" ,"Balance" ,"Curve" ,"Acceleration",
           "Crossing", "Stamina", "Agility" ,"ShotPower",
           "SprintSpeed" ,"Strength","PreferredFoot"
  ]
  Value: [ "InternationalReputation", "Reactions", "Overall",
           "BallControl", "Penalties", "GKPositioning",
           "SlidingTackle", "StandingTackle",
           "ShortPassing", "Jumping", "Interceptions",
           "Finishing", "GKKicking", "HeadingAccuracy",
           "Aggression", "LongPassing", "GKHandling",
           "Volleys", "Vision", "LongShots",
           "GKReflexes", "GKDiving", "Positioning",
           "SkillMoves" ,"Dribbling" ,"FKAccuracy",
           "Marking" ,"Balance" ,"Curve" ,"Acceleration",
           "Crossing", "Stamina", "Agility" ,"ShotPower",
           "SprintSpeed" ,"Strength"
  ]


forecasting:
  todos_los_modelos: False #mostrar las predicciones con todos los modelos o solo el mejor

nombre_dir_modelos: "assets/modelosFinales/"
nombre_dir_mejores_modelos: "assets/mejoresModelos/"
nombre_dir_modelos_pruebas: "assets/pruebasModelos/"
nombre_dir_reportes_cv: "reports/resultados_entrenamiento_cv/"
nombre_dir_reportes_finales: "reports/resultados_finales/"
nombre_dir_reportes_plots_all: "reports/plots/all/"
nombre_dir_reportes_plots_test: "reports/plots/test/"
entrenamiento:

  reportar_entrenamiento: True #para guardar o no el reporte del entrenamiento

  plot: True #variable para hacer plots o no durante el entrenamiento
  random_seed: 10
  train_test_split: 0.7
  optimizar: False

  entrenamiento_multiple_random: False #si entrenar un modelo con parametros ya fijos
  #utilizando  multiples separaciones train-validation para ver la consitencia del modelo en las predicciones en validacion
  #para comparar los mejores modelos y ver si alguno es consistentemente mejor que otro
  n_separaciones_aleatorias: 100 #parametro que se utiliza si el anterior es True

  normalize_X: True #si normalize_X=True y scale_X=False se usa standar scaler y si no max-min scaler
  scale_X: False #para activar max-min scaler
  reducir_dimensionalidad: False #usar pca para reducir la dimensionalidad

  feature_clasificacion: "PositionGrouped"  # variable que se quiere predecir con el modelo de clasificacion
  feature_regresion: "Wage"  #variable que se quiere predecir con el modelo de regresion

  features_regresion: ["Value", "Wage"]
  features_clasificacion: ["Position","PositionGrouped","PositionSinLado"]


  search: "grid"  #tipo de busqueda si se hace optmizacion, grid o random
  cv: 8 # numero de grupos de cross validation
  random_search:
    n_iter: 20 #numero de combinaciones del espacio parametrico utilizadas si se hace random search

  classification: #parametros exclusivos de clasificacion
    multi_class_score: "macro" #forma de computar las metricas con multi clase. Micro agrega todas las clases
                                #y macro calcula clase a clase y hace la media
    modelos : [ "lda"
                ] #modelos a utilizar en train_all para clasificacion

    todos: [ "random_forest",
               "gradient_boosting", "ada_boosting",
               "linear_SVC", "logistic",
               "k_neighbors", "lda", "SVC" ] #todos los modelos considerador
    param_tunning: #parametros fijos
      decision_tree:
        # minimo, maximo y step
        max_depth: [ 3,20,1 ] # default None
        min_samples_split: [ 2, 30, 10 ] # default 2
      random_forest:
        n_estimators: [20,30,50,60,80,100]
        min_samples_split: [ 2,21,3 ]
      lda:
        #shrinkage: [0,1.1,0.1]
        solver: ["svd","lsqr", "eigen"]

      linear_SVC:
        C: [ 1,2,3 ]
      gradient_boosting:
        max_depth: [ 3,6,9,12 ] #default 3
        n_estimators: [ 100 ] #default 100
        learning_rate: [ 0.1 ] #default 0.1
      ada_boosting: #por defecto usa como estimador base decission tree con max_depth=1
        n_estimators: [ 100 ] # default 50
        learning_rate: [ 1 ] #default 1
      k_neighbors:
        n_neighbors: [ 5,50,5 ]
        weights: [ "uniform","distance"]
      SVC:
        C: [ 0.5,2.2,0.1 ]
        degree: [1,2,3,4,5]
        kernel: ["poly"]

    params: #parametros a optimizar
        linear_SVC:
          multi_class: "ovr" #one vs rest, la otra opcion es crammer_singer
        logistic:
          multi_class: "ovr"
        random_forest:
          min_samples_split: 18
          #max_depth: 20
          n_estimators: 50
        k_neighbors:
          weights:  "uniform"
          n_neighbors: 40

        lda:
          #shrinkage: 0.1
          solver: "lsqr"
        SVC:
           C: 2.1
           gamma: "scale"
           kernel: "rbf"


        gradient_boosting:
          max_depth: 5 #default 3
          n_estimators: 100 #default 100
          learning_rate:  0.1  #default 0.1
        ada_boosting: #por defecto usa como estimador base decission tree con max_depth=1
          n_estimators:  10  # default 50
          learning_rate: 0.1  #default 1




  regression: #parametros exclusivos de regresion
    transformacion_logaritmica: True # para transformar el feature con log (util para lasso, ridge y linear
                                      # porque tanto Wage como Value son exponenciales)
    normalize_y: False #para transformar el feature normalizando (util para los metodos de gradiente
                      # porque se normaliza X e y para tener el error en la misma escala que las variables)



    modelos: [ "elastic_net"] #modelos a probar en train_all

    todos: [ "ridge", "lasso", "linear",
              "k_neighbors", "random_forest",
              "gradient_boosting","linear_SVR",
              "elastic_net","SVR"] #todos los modelos considerados

  #configuracion para la optimizacion de parametros
    param_tunning: #parametros a optimizar

      k_neighbors:
        n_neighbors: [ 5,50,1 ]
        weights: [ "uniform" ]
      random_forest:

        n_estimators: [ 20,30,50,60,80,100 ]
        min_samples_split: [ 2,21,4 ]

      elastic_net:
        l1_ratio: [0.05,1,0.05]

      gradient_boosting:
        max_depth: [10,15,20,25,30]
        n_estimators: [ 100,120,130,140,150] #default 100
        learning_rate: [0.05]
      linear_SVR:
        C: [ 0.5, 5, 0.2 ]
      SVR:
        C: [0.5,2.2,0.1]
        epsilon: [0.02,0.2,0.01]
        degree: [2,3,4,5]
        kernel: ["rbf","linear","poly"]





    params: #parametros fijos
      k_neighbors:
          metric: "minkowski"
          n_neighbors: 20
          weights: "uniform"

      random_forest:
        n_estimators: 100
        min_samples_split: 2
        max_depth:  10

      gradient_boosting:
        learning_rate: 0.05 #default 0.1
        max_depth: 10
        n_estimators: 140

      linear_SVR:
        C: 0.5

      SVR:
        C: 1.0
        kernel:  "rbf"
        gamma:  "scale"
        epsilon: 0.06
      elastic_net:
        l1_ratio: 0.95














